{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import config variables\n",
    "from config import *\n",
    "\n",
    "# import libraries\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import numpy as np, pandas as pd, math\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import sys, threading\n",
    "import gzip, h5py, os\n",
    "import statsmodels.api as sm\n",
    "import tqdm\n",
    "import time\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.calibration import calibration_curve, CalibrationDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up base config\n",
    "sim = 1\n",
    "prefix = f\"output/sim{sim}/\"\n",
    "variant_type = 'top_diff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True PRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load true risk data\n",
    "true_f = h5py.File(f\"{prefix}true_prs/prs_m_1000_h2_0.5_{variant_type}.hdf5\",\"r\")\n",
    "\n",
    "# label for each individual in the data\n",
    "true_labels = true_f[\"labels\"][()]\n",
    "# true PRS\n",
    "true_standardized_prs = true_f[\"G\"][()]\n",
    "# environmental effect from true PRS\n",
    "true_E = true_f[\"E\"][()]\n",
    "\n",
    "true_train_cases_ceu = true_f[\"train_cases_ceu\"][()]\n",
    "true_train_controls_ceu = true_f[\"train_controls_ceu\"][()]\n",
    "true_train_cases_yri = true_f[\"train_cases_yri\"][()]\n",
    "true_train_controls_yri = true_f[\"train_controls_yri\"][()]\n",
    "\n",
    "# group labels\n",
    "zip_true_prs_and_E = list(zip(true_labels, true_standardized_prs, true_E))\n",
    "\n",
    "true_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe of true risk scores per each person in the true risk prs data\n",
    "true_prs_df = pd.DataFrame(zip_true_prs_and_E, columns=[\"group\", \"true_prs\", \"true_E\"])\n",
    "true_prs_df['group'] = true_prs_df['group'].map(lambda x: x.decode(\"utf-8\"))\n",
    "\n",
    "# subset of european and african ancestry individuals\n",
    "exclude_admix_mask = true_prs_df['group'].str.contains('ceu|yri') \n",
    "true_prs_df = true_prs_df[exclude_admix_mask]\n",
    "\n",
    "# add column for total trait liability\n",
    "true_prs_df = true_prs_df.assign(true_L = lambda x: x.true_prs + x.true_E) # where L is the total trait liability\n",
    "\n",
    "# subset european population\n",
    "ceu_mask = true_prs_df['group'].str.contains('ceu')  \n",
    "true_prs_df_ceu = true_prs_df[ceu_mask].copy()\n",
    "\n",
    "# subset african population\n",
    "yri_mask = true_prs_df['group'].str.contains('yri')  \n",
    "true_prs_df_yri = true_prs_df[yri_mask].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenotype (P) is 1 for the top 5% of people ranked by L (total trait liability)\n",
    "\n",
    "def get_true_phenotype_outcome(group_df):\n",
    "    # select the tail end of the total trait liability distribution as cases\n",
    "    select_percentage_of_cases = 0.05\n",
    "\n",
    "    selected_cases_in_group = group_df.sort_values('true_L').tail(int(group_df.shape[0] * select_percentage_of_cases))\n",
    "    first_case = selected_cases_in_group.head(1).true_L.squeeze()\n",
    "    last_case = selected_cases_in_group.tail(1).true_L.squeeze()\n",
    "\n",
    "    true_outcome = group_df['true_L'].between(first_case, last_case).astype(int)\n",
    "    \n",
    "    return true_outcome\n",
    "\n",
    "true_prs_df_ceu['true_outcome'] = get_true_phenotype_outcome(true_prs_df_ceu)\n",
    "true_prs_df_yri['true_outcome'] = get_true_phenotype_outcome(true_prs_df_yri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 10000\n",
    "\n",
    "def simulate_non_genetic_effect(group_df):\n",
    "    # e*_i ~ N(0, 1-h^2)\n",
    "    # mean = 0, variance (standard deviation) = (1-h^2)\n",
    "    mean, variance = 0, 1-H2\n",
    "    norm_dist = np.random.normal(mean, variance, size = int(group_df.shape[0]))\n",
    "    z_score = (norm_dist - norm_dist.mean())/ norm_dist.std()\n",
    "    \n",
    "    # E*_i = (e*_i - (mean of e*_i/SD of e*_i)) * sqrt(variance)) <- where variance is 1-h^2\n",
    "    expected_E = (z_score / norm_dist.std()) * math.sqrt(variance) \n",
    "\n",
    "    # standardized non-genetic effect (environmental noise)\n",
    "    return expected_E\n",
    "\n",
    "\n",
    "def simulate_phenotype_occurence(group_df, expected_E):\n",
    "    true_risk_scores = group_df[\"true_prs\"]\n",
    "    group_L_df = pd.DataFrame(list(zip(true_risk_scores, expected_E)), columns=[\"true_prs\", \"expected_E\"])\n",
    "\n",
    "    # total trait liability [L*_i] (expected_L) -> L*_i = G_i + E*_i\n",
    "    group_L_df = group_L_df.assign(expected_L = lambda x: x.true_prs + x.expected_E)\n",
    "\n",
    "    # select the tail end of the total trait liability distribution as cases\n",
    "    select_percentage_of_cases = 0.05\n",
    "    selected_cases = group_L_df.sort_values('expected_L').tail(int(group_L_df.shape[0] * select_percentage_of_cases))\n",
    "    first_case = selected_cases.head(1).expected_L.squeeze()\n",
    "    last_case = selected_cases.tail(1).expected_L.squeeze()\n",
    "\n",
    "    expected_P = group_L_df['expected_L'].between(first_case, last_case).astype(int).to_numpy()\n",
    "    \n",
    "    return expected_P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_E_multi_run_wrapper(group_df, group_name):\n",
    "    with mp.Pool() as pool:\n",
    "        print(\"Expected E for {}\".format(group_name))\n",
    "        expected_E_for_group = list(tqdm.tqdm(pool.imap(simulate_non_genetic_effect, [group_df for i in range(num_simulations)]), total=num_simulations))\n",
    "\n",
    "    return expected_E_for_group\n",
    "\n",
    "\n",
    "def simulated_phenotype_multi_run_wrapper(group_df, group_expected_Es, group_name):\n",
    "    p_func = partial(simulate_phenotype_occurence, group_df)\n",
    "    \n",
    "    with mp.Pool() as pool:\n",
    "        print(\"Expected P for {}\".format(group_name))\n",
    "        expected_group_P = list(tqdm.tqdm(pool.imap(p_func, [e for e in group_expected_Es]), total=len(group_expected_Es)))\n",
    "\n",
    "    return expected_group_P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expected standardized non-genetic effect per group\n",
    "# expected_E_CEU = expected_E_multi_run_wrapper(true_prs_df_ceu, \"CEU\")\n",
    "# expected_E_YRI = expected_E_multi_run_wrapper(true_prs_df_yri, \"YRI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expected occurrence of phenotype per group\n",
    "# expected_occurrence_P_CEU = simulated_phenotype_multi_run_wrapper(true_prs_df_ceu, expected_E_CEU, \"CEU\")\n",
    "# expected_occurrence_P_YRI = simulated_phenotype_multi_run_wrapper(true_prs_df_yri, expected_E_YRI, \"YRI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def expected_phenotype_probability(expected_Ps, group_df):\n",
    "#     expected_group_phenotype_probability = [sum(x)/num_simulations for x in zip(*expected_Ps)] \n",
    "    \n",
    "#     return expected_group_phenotype_probability\n",
    "\n",
    "# true_prs_df_ceu['true_prs_probability_of_outcome'] = expected_phenotype_probability(expected_occurrence_P_CEU, true_prs_df_ceu)\n",
    "# true_prs_df_yri['true_prs_probability_of_outcome'] = expected_phenotype_probability(expected_occurrence_P_YRI, true_prs_df_yri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical PRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_variant_type = variant_type\n",
    "prefix = 'output/sim1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob all empirical prs data files\n",
    "emp_prs_files_dir_prefix = f'{prefix}emp_prs/{emp_variant_type}/'\n",
    "file_name_glob_pattern = 'emp_prs_m_*_identifier_*[0-9]*.hdf5'\n",
    "\n",
    "emp_files = glob.glob(emp_prs_files_dir_prefix + file_name_glob_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_emp_data(emp_files):\n",
    "    all_emp_prs_list = []\n",
    "\n",
    "    for file in emp_files:\n",
    "        cases = re.search('weights_(.*?)cases_identifier', file).group(1)\n",
    "        identifier = re.search('identifier_(.*?).hdf5', file).group(1)\n",
    "        snps = re.search('1_(.*?)_snps_', file).group(1)\n",
    "        weights = re.search('cases_(.*?)_weights', file).group(1)\n",
    "    \n",
    "        # open emp prs file\n",
    "        f = h5py.File(file, 'r')\n",
    "        \n",
    "        # extra individuals and their empirical risk scores\n",
    "        emp_prs = f['X'][()]\n",
    "        emp_labels = f[\"labels\"][()]\n",
    "        \n",
    "        zip_data = list(zip(emp_labels, emp_prs))\n",
    "        \n",
    "        # create a dictionary of the file identifier, number of cases sampled, population snps, population weights,\n",
    "        # and the labeled individuals and their risk scores\n",
    "        data_dict = {'id': identifier, 'cases': cases, 'snps': snps, 'weights': weights, 'emp_prs': zip_data}\n",
    "        \n",
    "        all_emp_prs_list.append(data_dict)\n",
    "        \n",
    "        f.close()\n",
    "    \n",
    "    return all_emp_prs_list\n",
    "    \n",
    "# load all empirical risk data into list from files\n",
    "all_emp_prs = load_all_emp_data(emp_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emp_prs_cases_controls_data(identifier):\n",
    "    suffix = f\"identifier_{identifier}\"\n",
    "    prefix = 'output/sim1/'\n",
    "    \n",
    "    cases_dir_prefix = f'{prefix}emp_prs/{emp_variant_type}/cases/'\n",
    "    ceu_cases_pattern = f\"{cases_dir_prefix}CEU_train_cases\"\n",
    "    yri_cases_pattern = f\"{cases_dir_prefix}YRI_train_cases\"\n",
    "\n",
    "    control_dir_prefix = f'{prefix}/emp_prs/{emp_variant_type}/control/'\n",
    "    ceu_control_pattern = f\"{control_dir_prefix}CEU_control\"\n",
    "    yri_control_pattern = f\"{control_dir_prefix}YRI_control\"\n",
    "\n",
    "    cases = glob.glob(cases_dir_prefix+'*')\n",
    "    controls = glob.glob(control_dir_prefix+'*')\n",
    "    \n",
    "    # file for all ceu cases for the given identifier\n",
    "    ceu_cases = [i for i in cases if i.startswith(ceu_cases_pattern) and i.endswith(suffix)]\n",
    "    # file for all yri cases for the given identifier\n",
    "    yri_cases = [i for i in cases if i.startswith(yri_cases_pattern) and i.endswith(suffix)]\n",
    "\n",
    "    # file for all ceu control for the given identifier\n",
    "    ceu_control = [i for i in controls if i.startswith(ceu_control_pattern) and i.endswith(suffix)]\n",
    "    # file for all yri cases for the given identifier\n",
    "    yri_control = [i for i in controls if i.startswith(yri_control_pattern) and i.endswith(suffix)]\n",
    "\n",
    "    cases_control_files_dict = {\n",
    "        'ceu_cases': ceu_cases, \n",
    "        'yri_cases': yri_cases,\n",
    "        'ceu_control': ceu_control,\n",
    "        'yri_control': yri_control\n",
    "    }\n",
    "    \n",
    "    for label, file in cases_control_files_dict.items():\n",
    "        assert len(file) == 1, \"the list confirmed has 1 item\"\n",
    "        with open(file[0]) as temp_file:\n",
    "            l = [line.rstrip('\\n') for line in temp_file]\n",
    "            # remove first zero element from all\n",
    "            l.pop(0)\n",
    "        # dictionary value is now a list of indices from the given case or control file\n",
    "        cases_control_files_dict[label] = l\n",
    "\n",
    "    return cases_control_files_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Learning Curve Data for Empirical Risk Score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_learning_curve_data(list_of_emp_prs_files):\n",
    "    list_of_probabilities_per_emp_prs_file = []\n",
    "        \n",
    "    for file in list_of_emp_prs_files:\n",
    "        cases = file['cases']\n",
    "        snps = file['snps']\n",
    "        weights = file['weights']\n",
    "        identifier = file['id']\n",
    "\n",
    "        zip_emp_prs = file['emp_prs']\n",
    "                        \n",
    "        if np.isnan(zip_emp_prs[1][1]):\n",
    "            continue\n",
    "            \n",
    "        emp_prs_df = pd.DataFrame(zip_emp_prs, columns=[\"group\", \"emp_prs\"])\n",
    "        emp_prs_df['group'] = emp_prs_df['group'].map(lambda x: x.decode(\"utf-8\"))\n",
    "\n",
    "        # load the data for ceu and yri separately\n",
    "        ceu_mask = emp_prs_df['group'].str.contains('ceu') \n",
    "        # each row is a person in european population\n",
    "        emp_prs_df_ceu = emp_prs_df[ceu_mask].copy()\n",
    "\n",
    "        yri_mask = emp_prs_df['group'].str.contains('yri')\n",
    "        # each row is a person in african population\n",
    "        emp_prs_df_yri = emp_prs_df[yri_mask].copy()\n",
    "        \n",
    "        # add true phenotype outcome to empirical risk scores for each group\n",
    "        emp_prs_df_ceu['true_outcome'] = true_prs_df_ceu['true_outcome'].copy()\n",
    "        emp_prs_df_yri['true_outcome'] = true_prs_df_yri['true_outcome'].copy()\n",
    "        \n",
    "        emp_prs_df_ceu['training_size'] = cases\n",
    "        emp_prs_df_yri['training_size'] = cases\n",
    "        \n",
    "        emp_prs_df_ceu['identifier'] = identifier\n",
    "        emp_prs_df_yri['identifier'] = identifier\n",
    "        \n",
    "        emp_prs_df_ceu['snps'] = snps\n",
    "        emp_prs_df_yri['snps'] = snps\n",
    "        \n",
    "        emp_prs_df_ceu['weights'] = weights\n",
    "        emp_prs_df_yri['weights'] = weights\n",
    "        \n",
    "        # subset cases and control training data for each identifier\n",
    "        cases_control_files_dict = get_emp_prs_cases_controls_data(identifier)\n",
    "                \n",
    "        ceu_training_data = cases_control_files_dict['ceu_cases'] + cases_control_files_dict['ceu_control']\n",
    "        ceu_training_data = [f'ceu_{i}' for i in ceu_training_data]\n",
    "        \n",
    "        yri_training_data = cases_control_files_dict['yri_cases'] + cases_control_files_dict['yri_control']\n",
    "        yri_training_data = [f'yri_{i}' for i in yri_training_data]\n",
    "\n",
    "        emp_prs_df_ceu['is_in_training_data'] = np.where(emp_prs_df_ceu.group.isin(ceu_training_data), 1, 0)\n",
    "        emp_prs_df_yri['is_in_training_data'] = np.where(emp_prs_df_yri.group.isin(yri_training_data), 1, 0)\n",
    "    \n",
    "        print(f\"Saving {emp_variant_type} data for CEU with {cases} cases and {snps} snps..\")\n",
    "        emp_prs_df_ceu.to_csv(f\"learning_curve_data/{emp_variant_type}/ceu_emp_prs_{emp_variant_type}_cases_{cases}_snps_{snps}_id_{identifier}.csv\", index=False)\n",
    "\n",
    "        print(f\"Saving {emp_variant_type} data for YRI with {cases} cases and {snps} snps..\")\n",
    "        emp_prs_df_yri.to_csv(f\"learning_curve_data/{emp_variant_type}/yri_emp_prs_{emp_variant_type}_cases_{cases}_snps_{snps}_id_{identifier}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving top_diff data for CEU with 3000 cases and yri snps..\n",
      "Saving top_diff data for YRI with 3000 cases and yri snps..\n",
      "Saving top_diff data for CEU with 5000 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 5000 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 4000 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 4000 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 1000 cases and yri snps..\n",
      "Saving top_diff data for YRI with 1000 cases and yri snps..\n",
      "Saving top_diff data for CEU with 8000 cases and yri snps..\n",
      "Saving top_diff data for YRI with 8000 cases and yri snps..\n",
      "Saving top_diff data for CEU with 10000 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 10000 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 6000 cases and yri snps..\n",
      "Saving top_diff data for YRI with 6000 cases and yri snps..\n",
      "Saving top_diff data for CEU with 400 cases and yri snps..\n",
      "Saving top_diff data for YRI with 400 cases and yri snps..\n",
      "Saving top_diff data for CEU with 10000 cases and yri snps..\n",
      "Saving top_diff data for YRI with 10000 cases and yri snps..\n",
      "Saving top_diff data for CEU with 4000 cases and yri snps..\n",
      "Saving top_diff data for YRI with 4000 cases and yri snps..\n",
      "Saving top_diff data for CEU with 2000 cases and yri snps..\n",
      "Saving top_diff data for YRI with 2000 cases and yri snps..\n",
      "Saving top_diff data for CEU with 800 cases and yri snps..\n",
      "Saving top_diff data for YRI with 800 cases and yri snps..\n",
      "Saving top_diff data for CEU with 9000 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 9000 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 3000 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 3000 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 5000 cases and yri snps..\n",
      "Saving top_diff data for YRI with 5000 cases and yri snps..\n",
      "Saving top_diff data for CEU with 800 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 800 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 400 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 400 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 1000 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 1000 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 7000 cases and yri snps..\n",
      "Saving top_diff data for YRI with 7000 cases and yri snps..\n",
      "Saving top_diff data for CEU with 8000 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 8000 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 2000 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 2000 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 9000 cases and yri snps..\n",
      "Saving top_diff data for YRI with 9000 cases and yri snps..\n",
      "Saving top_diff data for CEU with 7000 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 7000 cases and ceu snps..\n",
      "Saving top_diff data for CEU with 6000 cases and ceu snps..\n",
      "Saving top_diff data for YRI with 6000 cases and ceu snps..\n"
     ]
    }
   ],
   "source": [
    "generate_learning_curve_data(all_emp_prs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prs",
   "language": "python",
   "name": "prs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
